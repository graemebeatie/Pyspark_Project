{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pyspark Testing\n",
    "\n",
    "I am following along with the freeCodeCamp video to try out pyspark: https://www.youtube.com/watch?v=_C8kWso4ne4 \n",
    "\n",
    "I had to install the ucimlrepo dataset in the conda env to be able to import ucimlrepo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import ucimlrepo\n",
    "import os\n",
    "\n",
    "\n",
    "os.environ[\"JAVA_HOME\"] = \"C:\\Program Files\\Java\\jdk-21\"\n",
    "os.environ[\"SPARK_HOME\"] = \"C:\\Spark\\spark-3.5.0-bin-hadoop3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
      "0   63    1   1       145   233    1        2      150      0      2.3      3   \n",
      "1   67    1   4       160   286    0        2      108      1      1.5      2   \n",
      "2   67    1   4       120   229    0        2      129      1      2.6      2   \n",
      "3   37    1   3       130   250    0        0      187      0      3.5      3   \n",
      "4   41    0   2       130   204    0        2      172      0      1.4      1   \n",
      "\n",
      "    ca  thal  \n",
      "0  0.0   6.0  \n",
      "1  3.0   3.0  \n",
      "2  2.0   7.0  \n",
      "3  0.0   3.0  \n",
      "4  0.0   3.0        num\n",
      "0      0\n",
      "1      2\n",
      "2      1\n",
      "3      0\n",
      "4      0\n",
      "..   ...\n",
      "298    1\n",
      "299    2\n",
      "300    3\n",
      "301    1\n",
      "302    0\n",
      "\n",
      "[303 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo, list_available_datasets\n",
    "\n",
    "# check which datasets can be imported\n",
    "# list_available_datasets()\n",
    "\n",
    "# import dataset\n",
    "heart_disease = fetch_ucirepo(id=45)\n",
    "# alternatively: fetch_ucirepo(name='Heart Disease')\n",
    "\n",
    "# access data\n",
    "X = heart_disease.data.features\n",
    "y = heart_disease.data.targets\n",
    "# sklearn.linear_model.LinearRegression().fit(X, y)\n",
    "\n",
    "# # access metadata\n",
    "# print(heart_disease.metadata.uci_id)\n",
    "# print(heart_disease.metadata.num_instances)\n",
    "# print(heart_disease.metadata.additional_info.summary)\n",
    "\n",
    "# access variable info in tabular format\n",
    "# print(heart_disease.variables)\n",
    "print(X.head(),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(type(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('Practice').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://GLaptop:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practice</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1f7ed7d8350>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
